\chapter{提案手法}

本章では，本研究における提案モデルについて述べる．
\ref{sec:提案への着想}節では，提案モデルへの着想について述べる．
\ref{sec:ラベル付け}節では，ラベルなしデータの中でラベル付けを行うデータの抽出方法について述べる．
\ref{sec:提案手法アルゴリズム}節では，提案手法アルゴリズムを示す．
提案モデルではSemiBoostを二値分類から多値分類へ拡張する手法を提案し，分類精度の向上を図る．
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{提案への着想}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\label{sec:提案への着想}
SemiBoostは半教師あり学習の二値分類問題において有効な手法である．しかしながらこの手法は二値分類問題にのみ適用可能な手法であるため，多値分類問題への拡張が望まれる．そこで二値分類器を多値分類に拡張する手法としてECOC法が挙げられる．ECOC法の1-versus-the rest法などを用いることで多値分類へ拡張することができる．\par

1-versus-the rest法を用いてSemiBoostを多値分類へ拡張することを考えた場合，分類器の出力を確率値とすることでカテゴリを直接推定できる．しかしながら，半教師あり学習で用いる少数のラベルありデータは，何らかの行動の結果として得られているデータであり，実際のデータ分布に従ったランダムサンプリングではない場合がある．このときSemiBoostを1-versus-the rest法に直接適用すると，異なるカテゴリを二つにまとめて二値分類するため，分類する二つの分布が特徴空間上離れた位置関係ではなくなり，SemiBoostが上手く機能せず分類精度が悪化する可能性がある．これは，正しく仮ラベルが付与されるラベルなしデータが少なくなり，誤った仮ラベルの付与されたデータの割合が多くなることに起因する．\par
\newpage
そこで本研究ではECOC法にSemiBoostを適用し，ラベルなしデータに付与された仮ラベルの信頼性が高いデータのみを仮ラベルありデータとして抽出する．そしてラベルありデータと信頼度の高い仮ラベルありデータを学習データとして教師あり学習を行う．提案手法では，ECOC法にSemiBoostを適用し，ラベルなしデータのうち信頼性の高いデータのみを抽出するため，ECOC法を直接適用したときの問題点を克服し，多値分類への拡張を行うことが可能となる．\par


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{ラベルなしデータの仮ラベル付け}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\label{sec:ラベル付け}


提案手法では，ECOC法の一つである1-versus-the rest法を用いて多値分類を行う．あるカテゴリの符号語$\bm{W}_{c_k}$とSemiBoostによる二値分類の出力ベクトル$\bm{g}$のハミング距離が$0$となるラベルなしデータのみにカテゴリ$c_k$のラベルを付与し，このデータを仮ラベルありデータとする．その結果，複数のカテゴリに所属すると判断された信頼度の低いデータは誤った分類を引き起こす要因となる可能性があるため取り除き，信頼度の高いラベルのみを学習データに追加することが可能となる．

\begin{figure}[H]
\begin{center}
表4.1:符号表の例($K = 4$)
\label{4cate}
\includegraphics[width=10.0cm]{1vs.png}
\end{center}
\end{figure}\par

表4.1を用いて例を挙げると，SemiBoostによる二値分類の出力ベクトル$\bm{g}=({1}, {-1}, {-1}, {-1})$のようなときは$c_1$とのハミング距離が0となるため$c_1$としてラベルを付与する．一方，$\bm{g}=({1}, {-1}, {1}, {-1})$のときはハミング距離が0となるカテゴリが存在せず，最小距離復号を行っても$c_1, c_3$のどちらに所属するか判断できないので，このデータにラベルを付与しない．\par


ラベルなしデータにラベルを付与することで，学習に使用するデータの数が増加し，教師あり学習の分類精度の向上が期待される．\par


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{提案手法アルゴリズム}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\label{sec:提案手法アルゴリズム}

\begin{description}
  \item[Step1)] 学習データを用い，1-vs-the rest法に従って構成された各二値分類器を，SemiBoostにより学習する．

  \item[Step2)]Step1の出力結果から，ラベルなしデータと各カテゴリとのハミング距離を算出する．

  \item[Step3)]ラベルなしデータのうち，ハミング距離が$0$となるカテゴリをもつデータにそのカテゴリを付与して仮ラベルありデータとする．

  \item[Step4)] Step3で得られた仮ラベルありデータとラベルありデータを用いて，教師あり学習を行い新規入力データの所属カテゴリを推定する．
\end{description}

%\newpage
上記の提案アルゴリズムを図を用いて説明する．\par
図\ref{bunpu1}のようなデータの分布を仮定して説明する．この分布は各カテゴリにおいてラベルを付与したデータが一部の区間にのみ存在するような問題設定を考える．例では，カテゴリ数を3とする．
\begin{figure}[H]
\centering
\includegraphics[width=10.0cm]{bunpu1.png}
\caption{データ分布}
\label{bunpu1}
\end{figure}\par
\newpage
まず，Step1において1-vs-the rest法に従ってSemiBoostにより分類を行う．ここで各分類器の識別境界は図\ref{bunpu2}のようになるとする．識別境界はカテゴリ数分存在し，例では，3本境界が得られる．
\begin{figure}[H]
\centering
\includegraphics[width=10.0cm]{bunpu2.png}
\caption{Step1の識別境界}
\label{bunpu2}
\end{figure}\par

%\newpage
図\ref{bunpu2}のような識別境界をもとに所属カテゴリを確率値として出力し，復号すると図\ref{bunpu3}のような識別境界が得られる．

\begin{figure}[H]
\centering
\includegraphics[width=10.0cm]{bunpu3.png}
\caption{直接多値分類に拡張した場合の分類境界}
\label{bunpu3}
\end{figure}\par

しかしながら，SemiBoostは複数の分布をまとめたとき，複数のカテゴリをまとめたデータ分布が複雑になり，良い識別境界を得られないため，直接多値分類に拡張した場合の識別境界は好ましくない．\par

そこでStep3により1-vs-the rest法の各分類器の結果をハミング距離によって，確実にいずれかのカテゴリに所属すると判断されるものを見つけ出し，このようなラベルなしデータのみに新たにラベルの付与を行う．その結果を図\ref{bunpu4}に示す．

\begin{figure}[H]
\centering
\includegraphics[width=10.0cm]{bunpu4.png}
\caption{ラベルなしデータへのラベルの付与}
\label{bunpu4}
\end{figure}\par

%\newpage
最後にStep4で，Step3において付与したラベルを用いて教師あり分類を行う．このときの分類結果を図\ref{bunpu6}に示す．このときの分類境界は直接分類したときと比較して，分類しやすいカテゴリの分類精度が上がると考えられる．

\begin{figure}[H]
\centering
\includegraphics[width=10.0cm]{bunpu6.png}
\caption{Step4による分類結果}
\label{bunpu6}
\end{figure}





