\chapter{評価実験}

本章では，提案モデルの有用性を検証するため，人工データを生成しモデルの検証を行った．
また，UCI機械学習レポジトリのデータを提案モデルに適用し実際のデータによる検証も行った．
%\newpage
\section{人工データを用いた実験}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{人工データを用いた実験及び実験条件}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\label{sec:人工データを用いた実験及び実験条件}
人工データを用いて提案手法の有効性を示す．\par

本実験で生成するデータのカテゴリ数は4，データの次元数$d = 12$とする．半教師あり学習で用いる少数のラベルありデータは，何らかの行動の結果として得られているデータであり，実際のデータ分布に従ったランダムサンプリングではない場合がある．そのため，サンプリングしたデータを偏らせることを目的とし，各カテゴリごとに5つの正規分布を連ねて作成する．\par
$c_1$は以下の5つの重心ベクトルから分散1の正規分布に従う乱数を生成する．\par
\begin{center}
表5.1.人工データの重心ベクトル($c_1$)\\
\scalebox{0.75}[0.8]{
\begin{tabular}{|c|c|}
\hline
&重心ベクトル\\
\hline\hline
1つ目&$(-3,-3,-3,-3,-3,-2,-2,-2,-2,-2)$\\
\hline
2つ目&$(-3,-3,-3,-3,-3,-1,-1,-1,-1,-1)$\\
\hline
3つ目&$(-3,-3,-3,-3,-3, 0, 0, 0, 0, 0)$\\
\hline
4つ目&$(-3,-3,-3,-3,-3, 1, 1, 1, 1, 1)$\\
\hline
5つ目&$(-3,-3,-3,-3,-3, 2, 2, 2, 2, 2)$\\
\hline
\end{tabular}
}
\end{center}\par

\newpage
$c_2$は以下の5つの重心ベクトルから分散1の正規分布に従う乱数を生成する．\par

\begin{center}
表5.2.人工データの重心ベクトル($c_2$)\\
\scalebox{0.75}[0.8]{
\begin{tabular}{|c|c|}
\hline
&重心ベクトル\\
\hline\hline
1つ目&$(-1,-1,-1,-1,-1,-2,-2,-2,-2,-2)$\\
\hline
2つ目&$(-1,-1,-1,-1,-1,-1,-1,-1,-1,-1)$\\
\hline
3つ目&$(-1,-1,-1,-1,-1,0,0,0,0,0)$\\
\hline
4つ目&$(-1,-1,-1,-1,-1,1,1,1,1,1)$\\
\hline
5つ目&$(-1,-1,-1,-1,-1,2,2,2,2,2)$\\
\hline
\end{tabular}
}
\end{center}\par

$c_3$は以下の5つの重心ベクトルから分散1の正規分布に従う乱数を生成する．\par

\begin{center}
表5.3.人工データの重心ベクトル($c_3$)\\
\scalebox{0.75}[0.8]{
\begin{tabular}{|c|c|}
\hline
&重心ベクトル\\
\hline\hline
1つ目&$(1,1,1,1,1,-2,-2,-2,-2,-2)$\\
\hline
2つ目&$(1,1,1,1,1,-1,-1,-1,-1,-1)$\\
\hline
3つ目&$(1,1,1,1,1,0,0,0,0,0)$\\
\hline
4つ目&$(1,1,1,1,1,1,1,1,1,1)$\\
\hline
5つ目&$(1,1,1,1,1,2,2,2,2,2)$\\
\hline
\end{tabular}
}
\end{center}\par

$c_4$は以下の5つの重心ベクトルから分散1の正規分布に従う乱数を生成する．\par

\begin{center}
表5.4.人工データの重心ベクトル($c_4$)\\
\scalebox{0.75}[0.8]{
\begin{tabular}{|c|c|}
\hline
&重心ベクトル\\
\hline\hline
1つ目&$(3,3,3,3,3,-2,-2,-2,-2,-2)$\\
\hline
2つ目&$(3,3,3,3,3,-1,-1,-1,-1,-1)$\\
\hline
3つ目&$(3,3,3,3,3, 0, 0, 0, 0, 0)$\\
\hline
4つ目&$(3,3,3,3,3, 1, 1, 1, 1, 1)$\\
\hline
5つ目&$(3,3,3,3,3, 2, 2, 2, 2, 2)$\\
\hline
\end{tabular}
}
\end{center}\par


\begin{figure}[H]
\centering
\includegraphics[width=9.0cm]{seisei1.png}
\caption{生成データのイメージ図}
\label{seisei}
\end{figure}\par

学習データは各カテゴリで1000個ずつデータを生成し，全データの生成数を$N=4000$個とする．生成データのイメージを図\ref{seisei}に示す．ラベルありデータは各カテゴリ内の正規分布いずれか一つから3個ずつ抽出するものとし，ラベルありデータの数を$N_L=12(3×4)$個とする．同様にテストデータを400個生成し，式(\ref{eq:eq15})の分類誤り率を10回算出し，その平均を分類精度として評価する．各実験でラベルありデータを再度抽出するものとした．

\begin{equation}
\label{eq:eq15}
分類誤り率 = 1-\frac{正しく分類したテストデータ数}{テストデータ数}
\end{equation}\par
人工データの概要を表5.5に示す．\par


\begin{center}
表5.5.人工データ概要\\
\scalebox{0.75}[0.8]{
\begin{tabular}{c|r|r|r|r|r|}
\hline
&カテゴリ数&次元数&ラベルなしデータ数&ラベルありデータ数&テストデータ数\\
\hline\hline
人工データ&4&10&3988&12 (3×4カテゴリ)&400\\
\hline
\end{tabular}
}
\end{center}\par

提案手法では，$K=4$の1-versus-the rest法を用いる．提案手法と比較手法で用いる教師あり分類器はRandomForests (RF), 1対他SVM とする．比較手法としてラベルありデータのみを用いた教師あり分類(ラベルありのみ)，直接SemiBoostをECOC法に適用した分類(直接分類した場合)を用いた．また下限値として，ラベルありとラベルなしデータ全てにラベルが振られたときの教師あり分類(全データラベルあり)の分類誤り率も示す．また，SemiBoostの弱分類器には決定木を用いた．


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{実験結果}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\label{sec:人工データを用いた実験結果}
以下の実験では各カテゴリでサンプルを抽出した分布の番号とそのときの実験結果を示す．

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{flushleft}
\large{\bfseries {分布1，6，11，16から抽出したときの実験結果}}
\end{flushleft}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\subsection{分布1，6，11，16から抽出したときの実験結果}
このときの分類誤り率を以下に示す．

\begin{figure}[H]
\centering
\includegraphics[width=10.0cm]{01061116rf.png}
\caption{分布1，6，11，16から抽出したときの分類誤り率(RandomForests)}
\end{figure}\par

\begin{figure}[H]
\centering
\includegraphics[width=10.0cm]{01061116svm.png}
\caption{分布1，6，11，16から抽出したときの分類誤り率(SVM)}
\end{figure}\par

ラベルありデータの分布が各カテゴリで全部同じ方向に偏っているときは，ラベルありデータのみで分類したときも良い精度になり提案手法でも同程度の分類精度になった．また，直接SemiBoostを用いて分類した場合，精度が悪化しており，SemiBoostの直接的な多値分類が難しいことがわかる．

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{flushleft}
\large{\bfseries {分布1，10，11，20から抽出したときの実験結果}}
\end{flushleft}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%\subsection{分布1，10，11，20から抽出したときの実験結果}
このときの分類誤り率を以下に示す．
\begin{figure}[H]
\centering
\includegraphics[width=10.0cm]{01101120rf.png}
\caption{分布1，10，11，20から抽出したときの分類誤り率(RandomForests)}
\end{figure}\par

\begin{figure}[H]
\centering
\includegraphics[width=10.0cm]{01101120svm.png}
\caption{分布1，10，11，20から抽出したときの分類誤り率(SVM)}
\end{figure}\par

分布が各分布で交互に外側に存在する場合，提案手法の有効性が示された．これはラベルありデータのみでは，ラベルありデータが少ないため精度が上がらない．しかしながら提案手法ではSemiBoostを用いたのちラベルを付与したデータが正しく増加したため精度が改善されたと考えられる．\par
この人工データセットにおいて提案手法の教師あり分類器はSVMよりRandomForestsの方が精度がよい．原因としてはデータセットの特徴量をRandomForestsが容易に重要な特徴量としてとらえやすいことが原因であると考えられる．

\section{UCIデータセットを用いた実験}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{実験データ及び実験条件}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\label{sec:実験条件}

データセットとして，UCI機械学習レポジトリ\cite{UCI}の drug consumption から，CannabisとNicotineの2種類を用いる．データセットのカテゴリ数は7，データの次元数は$d = 12$である．1885件のデータのうち$N_L=210(30×7)$個はラベルありデータ，$N_U=1675$件はラベルなしデータとする．ラベルありデータは5.2.2節の方法より$N_L$個抽出し，各実験でラベルありデータを再度抽出するものとした．実験結果は5分割交差検定を5回繰り返し行い，その平均を用いることとした．
提案手法では，$K=7$の1-versus-the rest法を用いる．提案手法と比較手法で用いる教師あり分類器はRandomForests (RF), 1対他SVM とする．比較手法としてラベルありデータのみを用いた教師あり分類(ラベルありのみ)，直接SemiBoostをECOC法に適用した分類(直接分類した場合)を用いた．また下限値としてラベルありとラベルなしデータ全てにラベルが振られたときの教師あり分類(全データラベルあり)，上限値としてランダムにデータを分類したとき(ランダム)の分類誤り率も示す．
%初期のラベルありデータ数を各カテゴリ30個全部ラベルあり
事前実験により，SemiBoostの分類器数$T=10$，ラベルありデータ数$N_L=210 (30\times7)$個，偏りのあるラベルありデータ割合を$\theta\%$とした．また，SemiBoostの分類器にはSVMを用いた．評価指標として人工と同様に分類誤り率を用いる．

%また，教師あり分類に用いる学習器はRandomForest, 1対他SVM とした．

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{ラベルありデータの抽出}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\label{sec:ラベルありデータの抽出}

本研究ではラベルありデータに偏りがある場合についても，提案手法の有効性を示すことを目的とする．そのためラベルありデータは，各カテゴリの重心ベクトルを求め，そこから最も遠い点を基準に，その近傍ラベルありデータのうち$\theta \%$の点をサンプリングすることで生成する．その後，ラベルありデータのうち残りの$(100 - \theta) \%$の点はランダムに抽出し，これらをラベルありデータとする．

\begin{figure}[H]
\centering
\includegraphics[width=10.0cm]{label.png}
\caption{ラベルありデータのサンプル法}
\label{label}
\end{figure}\par


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{実験結果}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\label{sec:実験結果}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{flushleft}
\large{\bfseries {$\theta=70\%$のときの実験結果}}
\end{flushleft}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%\subsection{$\theta=70\%$のときの実験結果}
偏りがあるデータの割合$\theta=70\%$のとき，各データセットにおける分類誤り率を以下に示す．


\begin{figure}[H]
\centering
\includegraphics[width=10.0cm]{canarf.png}
\caption{Canabisによる分類結果($\theta=70\%$)(RandomForests)}
\label{canarf}
\end{figure}\par
\begin{figure}[H]
\centering
\includegraphics[width=10.0cm]{canasvm.png}
\caption{Canabisによる分類結果($\theta=70\%$)(SVM)}
\label{canasvm}
\end{figure}\par
\begin{figure}[H]
\centering
\includegraphics[width=10.0cm]{nicorf.png}
\caption{Nicotineによる分類結果($\theta=70\%$)(RandomForests)}
\label{nicorf}
\end{figure}\par
\begin{figure}[H]
\centering
\includegraphics[width=10.0cm]{nicosvm.png}
\caption{Canabisによる分類結果($\theta=70\%$)(SVM)}
\label{nicosvm}
\end{figure}\par


図\ref{canarf}，図\ref{canasvm}，図\ref{nicorf}，図\ref{nicosvm}よりどちらのデータセットにおいても提案手法がラベルありデータのみを用いた教師あり分類，直接SemiBoostをECOC法に適用した分類より誤分類率が小さくなった．この結果により，仮ラベルを付与してから再度教師あり分類を行う提案手法の有効性が示された．\par


このとき，ラベルを付与したデータの数と付与したラベルの正解数合計と不正解数合計を以下の表に示す．

\begin{center}
表5.6.ラベル付け結果概要(Canabis)\\
\scalebox{0.75}[0.8]{
\begin{tabular}{c|r|r|r|r|r|r|r}
\hline
&1&2&3&4&5&6&7\\
\hline\hline
正しく付与したラベル&602&19&4&9&3&0&490\\
\hline
誤って付与したラベル&370&5&8&14&1&1&286\\
\hline
\end{tabular}
}
\end{center}\par
\begin{center}
表5.7.ラベル付け結果概要(Nicotine)\\
\scalebox{0.75}[0.8]{
\begin{tabular}{c|r|r|r|r|r|r|r}
\hline
&1&2&3&4&5&6&7\\
\hline\hline
正しく付与したラベル&1&23&16&4&0&82&155\\
\hline
誤って付与したラベル&1&8&30&1&0&199&15\\
\hline
\end{tabular}
}
\end{center}\par
\vspace{1.0cm}
これらの結果から付与したラベルが真のラベルと一致している割合がCanabisにおいて$62\%$，Nicotineにおいて$53\%$程度となった．この結果はラベル付けの正確さを示しており，この正解率は全てのデータにラベルを付与して分類を行った際の正解率以上となっているため，提案手法が有効であると考えられる．しかしながらラベルを付与したデータ数がカテゴリによって差があり，分類しやすいデータにはラベルが付与されやすく分類精度も良い傾向が見られた．
%\newpage
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{flushleft}
\large{\bfseries {$\theta$を変更したときの実験結果}}
\end{flushleft}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%\subsection{$\theta$を変更したときの実験結果}

次にラベルありデータが全て偏っている場合$\theta=100\%$，完全にランダムにサンプリングした場合$\theta=0\%$についても\ref{sec:実験条件}節の条件で実験を行う．\par
偏りがあるデータの割合$\theta=100\%$のとき，各データセットにおける分類誤り率を以下に示す．

\begin{figure}[H]
\centering
\includegraphics[width=10.0cm]{canabis1.png}
\caption{Canabisによる分類結果($\theta=100\%$)(RandomForests)}
\label{canabis1}
\end{figure}\par
\begin{figure}[H]
\centering
\includegraphics[width=10.0cm]{nicotine2.png}
\caption{Canabisによる分類結果($\theta=100\%$)(SVM)}
\label{canabis2}
\end{figure}\par



\begin{figure}[H]
\centering
\includegraphics[width=10.0cm]{nicotine1.png}
\caption{Nicotineによる分類結果($\theta=100\%$)(RandomForests)}
\label{nicotine1}
\end{figure}\par
\begin{figure}[H]
\centering
\includegraphics[width=10.0cm]{nicotine2.png}
\caption{Nicotineによる分類結果($\theta=100\%$)(SVM)}
\label{nicotine2}
\end{figure}\par

$\theta=100\%$として全てのデータを偏らせたとき，提案手法で教師あり分類器としてRandomForestsを使っているものは，ラベルありデータのみを用いた教師あり分類，直接SemiBoostをECOC法に適用した分類より誤分類率が小さくなった．ラベルありデータが偏った場合でも提案手法が有効であることが分かる．
しかしながら，提案手法でも教師あり分類器にSVMを使ったものは直接SemiBoostをECOC法に適用した分類より分類誤り率が大きくなった．これは偏りのあるデータの中にSVMのサポートベクトルとなる点があり，ラベルありデータのみのSVMと同様に好ましくない識別境界が引かれていると考えられる．\par
よってこの実験から偏りの大きなデータを多数含んでいる可能性がある場合，提案手法の教師あり分類器としてSVMが好ましくない可能性があると考えられる．\par

%\newpage
次に完全にランダムにサンプリングした場合$\theta=0\%$の，各データセットにおける分類誤り率を以下に示す．\par

\begin{figure}[H]
\centering
\includegraphics[width=10.0cm]{canabis3.png}
\caption{Canabisによる分類結果($\theta=0\%$)(RandomForests)}
\label{canabis1}
\end{figure}\par
\begin{figure}[H]
\centering
\includegraphics[width=10.0cm]{nicotine4.png}
\caption{Canabisによる分類結果($\theta=0\%$)(SVM)}
\label{canabis2}
\end{figure}\par


\begin{figure}[H]
\centering
\includegraphics[width=10.0cm]{nicotine3.png}
\caption{Nicotineによる分類結果($\theta=0\%$)(RandomForests)}
\label{nicotine1}
\end{figure}\par
\begin{figure}[H]
\centering
\includegraphics[width=10.0cm]{nicotine4.png}
\caption{Nicotineによる分類結果($\theta=0\%$)(SVM)}
\label{nicotine2}
\end{figure}\par

$\theta=0\%$としてランダムサンプリングを行った場合，提案手法ではラベルありデータのみで分類した場合と同程度の精度を示した．直接SemiBoostをECOC法に適用した分類の精度がラベルありデータのみで分類した場合より分類誤り率が大きいことからECOC法を直接SemiBoostに適用することは好ましくないことがわかる．しかしながら，提案手法ではこの精度が悪化する識別境界の影響を受けにくく，ラベルありデータのみで分類を行った場合の分類誤り率と同程度になった．\par

これらの結果から，提案手法は$\theta$の値が大きい偏りのあるデータに対して強く，$\theta$の値が小さい偏りのないデータのときにも精度が悪化しないことが示された．






